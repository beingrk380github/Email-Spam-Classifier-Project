{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3235802,"sourceType":"datasetVersion","datasetId":1961542},{"sourceId":7546029,"sourceType":"datasetVersion","datasetId":4394621}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <b><span style='color:#28838a'> | </span><span style='color:#fc7651'> Email Spam Classifier </span></b>\n### By : Rambabu Kumar","metadata":{}},{"cell_type":"markdown","source":"<center><img src='https://miro.medium.com/v2/resize:fit:920/1*CS-OYdiRLCBMBiOpEURy0g.png' \n     height=300px width=700px /></center>\n","metadata":{}},{"cell_type":"code","source":"# Import the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style\nimport seaborn as sns\nimport nltk #Natural Language Toolkit\n#To ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:14.385196Z","iopub.execute_input":"2024-02-03T13:27:14.385669Z","iopub.status.idle":"2024-02-03T13:27:14.394277Z","shell.execute_reply.started":"2024-02-03T13:27:14.385634Z","shell.execute_reply":"2024-02-03T13:27:14.392818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load data & print samples\ndf = pd.read_csv('/kaggle/input/email-spam-detection-dataset-classification/spam.csv',encoding='latin-1')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:35.231004Z","iopub.execute_input":"2024-02-03T13:27:35.231543Z","iopub.status.idle":"2024-02-03T13:27:35.265572Z","shell.execute_reply.started":"2024-02-03T13:27:35.231503Z","shell.execute_reply":"2024-02-03T13:27:35.263966Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's drop the non-relevant unnamed columns \ndf=df.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'],axis=1)\n\n# Renaming v1 & v2 as Category & Text\ndf=df.rename(columns={\"v1\":\"Category\",\"v2\":\"Text\"})\n\n#Sample post modifications\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:36.319898Z","iopub.execute_input":"2024-02-03T13:27:36.320372Z","iopub.status.idle":"2024-02-03T13:27:36.33972Z","shell.execute_reply.started":"2024-02-03T13:27:36.320336Z","shell.execute_reply":"2024-02-03T13:27:36.337901Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <b><span style='color:#28838a'> | </span><span style='color:#fc7651'> Exploratory Data Analysis</span></b>","metadata":{}},{"cell_type":"code","source":"#Let's check the length of the dataset\nprint(\" Total number of rows in the dataset are\", len(df))","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:37.699939Z","iopub.execute_input":"2024-02-03T13:27:37.700402Z","iopub.status.idle":"2024-02-03T13:27:37.70578Z","shell.execute_reply.started":"2024-02-03T13:27:37.700366Z","shell.execute_reply":"2024-02-03T13:27:37.704899Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = 'white'\nfig, ax = plt.subplots(1, 2, figsize=(15, 4))\nax = ax.flatten()\nvalue_counts = df['Category'].value_counts()\nlabels = value_counts.index.tolist()\ncolors =[\"#6782a8\", \"#ab90a0\" ]\n# Donut Chart\nwedges, texts, autotexts = ax[0].pie(\n    value_counts, autopct='%1.1f%%',textprops={'size': 9, 'color': 'white','fontweight':'bold' }, colors=colors,\n    wedgeprops=dict(width=0.35),  startangle=80,   pctdistance=0.85  )\n# circle\ncentre_circle = plt.Circle((0, 0), 0.6, fc='white')\nax[0].add_artist(centre_circle)\n\n# Count Plot\nsns.countplot(data=df, y=df['Category'], ax=ax[1], palette=colors, order=labels)\nfor i, v in enumerate(value_counts):\n    ax[1].text(v + 1, i, str(v), color='black',fontsize=10, va='center')\nsns.despine(left=True, bottom=True)\nplt.yticks(fontsize=9,color='black')\nax[1].set_ylabel(None)\nplt.xlabel(\"\")\nplt.xticks([])\nfig.suptitle('Spam - Ham Distribution', fontsize=15)\nplt.tight_layout(rect=[0, 0, 0.85, 1])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-03T13:27:38.289696Z","iopub.execute_input":"2024-02-03T13:27:38.290623Z","iopub.status.idle":"2024-02-03T13:27:38.724407Z","shell.execute_reply.started":"2024-02-03T13:27:38.290577Z","shell.execute_reply":"2024-02-03T13:27:38.722917Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Descriptive Summary of the dataset\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:39.199858Z","iopub.execute_input":"2024-02-03T13:27:39.200359Z","iopub.status.idle":"2024-02-03T13:27:39.225612Z","shell.execute_reply.started":"2024-02-03T13:27:39.20032Z","shell.execute_reply":"2024-02-03T13:27:39.223988Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 12px; background-color: #ffffff; font-size:140%; text-align:left\">\n    \n- The dataset has **4825 emails (86.6%)** labled as Ham while **747 (13.4%)** labaled as Spam.\n- \"ham\" is the predominant category.\n- The dataset contains 5,169 unique texts.\n- The most frequent text being \"Sorry, I'll call later,\" occurring 30 times.","metadata":{}},{"cell_type":"code","source":"#Let's create a column to check of each text & plot a histogram to check the distirbution\ndf['Length']=df['Text'].apply(len)\ndisplay(df.head())\n\n#distribution of the data\nimport plotly.express as px\nfig = px.histogram(df, x='Length', marginal='rug',\n                   title='Histogram of Text Length')\nfig.update_layout(\n    xaxis_title='Length',\n    yaxis_title='Frequency',\n    showlegend=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:42.749819Z","iopub.execute_input":"2024-02-03T13:27:42.750594Z","iopub.status.idle":"2024-02-03T13:27:42.881356Z","shell.execute_reply.started":"2024-02-03T13:27:42.750553Z","shell.execute_reply":"2024-02-03T13:27:42.880078Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets check the distribution against categories\nimport plotly.express as px\nfig = px.histogram(df, x='Length', color='Category', marginal='rug',\n                   title='Histogram of Text Length by Category')\nfig.update_layout(\n    xaxis_title='Length',\n    yaxis_title='Frequency',\n    showlegend=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:43.574741Z","iopub.execute_input":"2024-02-03T13:27:43.576344Z","iopub.status.idle":"2024-02-03T13:27:43.696929Z","shell.execute_reply.started":"2024-02-03T13:27:43.576283Z","shell.execute_reply":"2024-02-03T13:27:43.695376Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's Label the data as 0 & 1 i.e. Spam as 1 & Ham as 0\ndf.loc[:,'Category']=df.Category.map({'ham':0, 'spam':1})\ndf['Category'] = df['Category'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:27:45.364652Z","iopub.execute_input":"2024-02-03T13:27:45.365185Z","iopub.status.idle":"2024-02-03T13:27:45.38594Z","shell.execute_reply.started":"2024-02-03T13:27:45.365145Z","shell.execute_reply":"2024-02-03T13:27:45.384596Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install wordcloud","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-03T13:27:45.925175Z","iopub.execute_input":"2024-02-03T13:27:45.925741Z","iopub.status.idle":"2024-02-03T13:28:00.89632Z","shell.execute_reply.started":"2024-02-03T13:27:45.9257Z","shell.execute_reply":"2024-02-03T13:28:00.894814Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <b><span style='color:#28838a'> </span><span style='color:#fc7651'> Word Cloud : Spam vs Ham </span></b>","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nspam = df[df['Category'] == 1]\nham = df[df['Category'] == 0]\nfont_path = \"/kaggle/input/fonts/acetone_font.otf\"\n\n# function to generate and display a WordCloud\ndef generate_wordcloud(data, title):\n    words = ' '.join(data['Text'])\n    wordcloud = WordCloud(stopwords=STOPWORDS, font_path=font_path,\n                          max_words=1500,\n                          max_font_size=350, random_state=42,\n                          width=2000, height=800,\n                          colormap=\"twilight\").generate(words)\n    plt.figure(figsize=(16, 8))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n\n# WordClouds for Spam and Ham\ngenerate_wordcloud(spam, 'Spam WordCloud')\ngenerate_wordcloud(ham, 'Ham WordCloud')","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:44:30.966199Z","iopub.execute_input":"2024-02-03T13:44:30.967287Z","iopub.status.idle":"2024-02-03T13:45:20.201731Z","shell.execute_reply.started":"2024-02-03T13:44:30.967214Z","shell.execute_reply":"2024-02-03T13:45:20.20022Z"},"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <b><span style='color:#28838a'> | </span><span style='color:#fc7651'> Bag of Words </span></b>","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ncount = CountVectorizer()\ntext = count.fit_transform(df['Text'])\n#Train & test split\nx_train, x_test, y_train, y_test = train_test_split(text, df['Category'], test_size=0.30, random_state=100)\ntext","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.786924Z","iopub.status.idle":"2024-02-03T13:16:07.787492Z","shell.execute_reply.started":"2024-02-03T13:16:07.787236Z","shell.execute_reply":"2024-02-03T13:16:07.78726Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's print the dimentions of the train & test dataset\ndisplay('X-Train :', x_train.shape)\ndisplay('X-Test :',x_test.shape)\ndisplay('Y-Train :',y_train.shape)\ndisplay('X-Test :',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.788993Z","iopub.status.idle":"2024-02-03T13:16:07.789605Z","shell.execute_reply.started":"2024-02-03T13:16:07.789318Z","shell.execute_reply":"2024-02-03T13:16:07.789349Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <b><span style='color:#28838a'> | </span><span style='color:#fc7651'> Training the ML models </span></b>","metadata":{}},{"cell_type":"markdown","source":"### <b><span style='color:#fc7651'> | </span><span style='color:#28838a'> Neural Network </span></b>","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.neural_network import MLPClassifier\n\nmlp_classifier_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000) \nmlp_classifier_model.fit(x_train, y_train)  \n\nprediction = mlp_classifier_model.predict(x_test)\n\n# Calculate and print classification metrics\nprint(\"MLP Classifier\")\nprint(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, prediction)))\nprint(\"Precision score: {:.2f}\".format(precision_score(y_test, prediction)))\nprint(\"Recall score: {:.2f}\".format(recall_score(y_test, prediction)))\nprint(\"F1 score: {:.2f}\".format(f1_score(y_test, prediction)))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.792193Z","iopub.status.idle":"2024-02-03T13:16:07.79274Z","shell.execute_reply.started":"2024-02-03T13:16:07.792505Z","shell.execute_reply":"2024-02-03T13:16:07.792531Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <b><span style='color:#fc7651'> | </span><span style='color:#28838a'> Multinomial Naive Bayes </span></b>","metadata":{}},{"cell_type":"code","source":"%%time\n# Multinomial Naive Bayes model \nfrom sklearn.naive_bayes import MultinomialNB\n\nmultinomial_nb_model = MultinomialNB()\nmultinomial_nb_model.fit(x_train, y_train)  # Train the model\n\nprediction = multinomial_nb_model.predict(x_test)\n\nprint(\"Multinomial NB\")\nprint(\"Accuracy score: {}\". format(accuracy_score(y_test, prediction)) )\nprint(\"Precision score: {}\". format(precision_score(y_test, prediction)) )\nprint(\"Recall score: {}\". format(recall_score(y_test, prediction)))\nprint(\"F1 score: {}\". format(f1_score(y_test, prediction)))","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.797892Z","iopub.status.idle":"2024-02-03T13:16:07.799133Z","shell.execute_reply.started":"2024-02-03T13:16:07.798755Z","shell.execute_reply":"2024-02-03T13:16:07.798796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <b><span style='color:#fc7651'> | </span><span style='color:#28838a'> Bernoulli Naive Bayes </span></b>","metadata":{}},{"cell_type":"code","source":"%%time\n# Bernoulli Naive Bayes model\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nbernoulli_nb_model = BernoulliNB()\nbernoulli_nb_model.fit(x_train, y_train)\n\nprediction = bernoulli_nb_model.predict(x_test)\n\n#Evaluation\nprint(\"Bernoulli NB\")\nprint(\"Accuracy score: {}\". format(accuracy_score(y_test, prediction)) )\nprint(\"Precision score: {}\". format(precision_score(y_test, prediction)) )\nprint(\"Recall score: {}\". format(recall_score(y_test, prediction)))\nprint(\"F1 score: {}\". format(f1_score(y_test, prediction)))","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.801236Z","iopub.status.idle":"2024-02-03T13:16:07.802251Z","shell.execute_reply.started":"2024-02-03T13:16:07.801898Z","shell.execute_reply":"2024-02-03T13:16:07.801932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <b><span style='color:#fc7651'> | </span><span style='color:#28838a'> Confusion Matrix </span></b>","metadata":{}},{"cell_type":"code","source":"#Confusion Matrix Subplot for 3 Models\nfrom sklearn.metrics import confusion_matrix\nmodels = [(\"Multinomial NB\", multinomial_nb_model), (\"Bernoulli NB\", bernoulli_nb_model),(\"MLP Classifier\", mlp_classifier_model) ]\n\nfig, axes = plt.subplots(1, 3, figsize=(10, 3))\nfor i, (model_name, model) in enumerate(models):\n    prediction = model.predict(x_test)\n    cm = confusion_matrix(y_test, prediction)\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n    axes[i].set_title(f\"{model_name} - Confusion Matrix\")\n    axes[i].set_xlabel(\"Predicted\")\n    axes[i].set_ylabel(\"Actual\")\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.804033Z","iopub.status.idle":"2024-02-03T13:16:07.804577Z","shell.execute_reply.started":"2024-02-03T13:16:07.804357Z","shell.execute_reply":"2024-02-03T13:16:07.80438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <b><span style='color:#fc7651'> | </span><span style='color:#28838a'> Metric Comparison Heatmap </span></b>","metadata":{}},{"cell_type":"code","source":"#Metric Comparison Heatmap\nmetric_data = []\nfor model_name, model in models:\n    prediction = model.predict(x_test)\n    accuracy = accuracy_score(y_test, prediction)\n    precision = precision_score(y_test, prediction)\n    recall = recall_score(y_test, prediction)\n    f1 = f1_score(y_test, prediction)\n    metric_data.append([accuracy, precision, recall, f1])\nmetric_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n#heatmap for metric comparison\nplt.figure(figsize=(6, 3))\nsns.heatmap(metric_data, annot=True, fmt=\".2f\", cbar=False, cmap=\"summer_r\", xticklabels=metric_labels, yticklabels=[model_name for model_name, _ in models])\nplt.title(\"Metric Comparison\")\nplt.yticks(rotation=0)\nplt.xlabel(\"Metrics\")\nplt.ylabel(\"Models\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:16:07.807391Z","iopub.status.idle":"2024-02-03T13:16:07.808901Z","shell.execute_reply.started":"2024-02-03T13:16:07.808569Z","shell.execute_reply":"2024-02-03T13:16:07.808605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 12px; background-color: #ffffff; font-size:140%; text-align:left\">\n\n<h3 align=\"left\"><font color=#fa592d>Conclusion</font></h3>\n\n* All three models perform exceptionally well, with high accuracy scores.\n* MLP Classifier leads in accuracy of 99%, followed by Bernoulli NB (98.39%), and Multinomial NB (98.15%)\n* Bernoulli NB achieves perfect precision (100%), indicating it has predicated correctly all the time.\n* MLP Classifier excels in F1 score of 94%\n* MLP Classifier has slightly lower recall 90% but compensates with higher precision.\n\n> **The final choice of model always depend upon what is needed to be filtered & hence model can be adjusted to improve recall or precision.**\n> - If you want to  minimize the number of false negatives i.e spam messages don't end up in the user's inbox you would like to have high Recall.\n> - On the other hand with high precision(false negatives), one might miss important messages because the model is overly cautious in classifying messages as spam.","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em; color:#fa592d;\">\n    <em>Never Click on unknown Links. Stay Safe.</em>\n</p>\n\n<center><img src='https://i.pinimg.com/originals/92/9e/c1/929ec1bf7d8fdac26d9fc33529bdbcb5.gif' \n     height=300px width=500px /></center>\n","metadata":{}},{"cell_type":"markdown","source":"\n# Notebook Ownership and Copyright\n\nThis Jupyter Notebook is owned and maintained by **Rambabu Kumar**.\n\n---\n\n<div style=\"text-align: center; font-size: 1.2em; margin-top: 20px;\">\n  This Project is made with ❤️ by Rambabu Kumar\n</div>\n\n---\n\n**Copyright © 2025 Rambabu Kumar. All rights reserved.**\n\nThis notebook and its contents are protected by copyright law. Unauthorized reproduction, distribution, or modification of this work, in whole or in part, is strictly prohibited.\n\"\"\"\n\n","metadata":{}}]}